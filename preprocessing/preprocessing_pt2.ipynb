{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Universidade do Estado do Rio de Janeiro\n","## Departamento de Engenharia de Sistemas e Computação - Tópicos Especiais A"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lecture 02 - Data Preprocessing: Categorical Data Transformation, Normalization, and Feature Selection\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In this lecture, we will cover some important aspects of data preprocessing for machine learning. Specifically, we will discuss how to transform categorical data, normalize numerical data, and perform feature selection. We will be using the Adult Income dataset from the UCI Machine Learning Repository as our example."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Loading the Dataset\n","Let's start by loading the dataset into our Python environment. We will be using the pandas library to work with our data."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6BsYOMxfhGV1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>income</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass  fnlwgt   education  education-num  \\\n","0   39          State-gov   77516   Bachelors             13   \n","1   50   Self-emp-not-inc   83311   Bachelors             13   \n","2   38            Private  215646     HS-grad              9   \n","3   53            Private  234721        11th              7   \n","4   28            Private  338409   Bachelors             13   \n","\n","        marital-status          occupation    relationship    race      sex  \\\n","0        Never-married        Adm-clerical   Not-in-family   White     Male   \n","1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n","2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n","3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n","4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n","\n","   capital-gain  capital-loss  hours-per-week  native-country  income  \n","0          2174             0              40   United-States   <=50K  \n","1             0             0              13   United-States   <=50K  \n","2             0             0              40   United-States   <=50K  \n","3             0             0              40   United-States   <=50K  \n","4             0             0              40            Cuba   <=50K  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n","columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n","           'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n","df = pd.read_csv(url, header=None, names=columns, na_values='?')\n","\n","# Print the first few rows of the dataset\n","df.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Transformation: Categorical Variables\n","\n","Many machine learning algorithms require numerical input data. However, some of the features in our dataset are categorical, such as workclass, education, marital-status, occupation, relationship, race, sex, and native-country. To use these features in our machine learning models, we need to transform them into numerical values."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Label Encoding\n","\n","One common way to transform categorical variables is to use label encoding. Label encoding involves assigning each unique category in a categorical feature with a numerical value. For example, we can encode the sex feature as follows:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 0]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Instantiate the LabelEncoder\n","le = LabelEncoder()\n","\n","# Fit and transform the 'sex' feature\n","df['sex'] = le.fit_transform(df['sex'])\n","\n","# Print the unique categories in the 'sex' feature\n","print(df['sex'].unique())\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1]\n"]}],"source":["# Instantiate the LabelEncoder\n","le = LabelEncoder()\n","\n","# Fit and transform the 'sex' feature\n","df['income'] = le.fit_transform(df['income'])\n","\n","# Print the unique categories in the 'sex' feature\n","print(df['income'].unique())\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### One-Hot Encoding\n","Another approach to transforming categorical variables is to use one-hot encoding. One-hot encoding involves creating a new binary feature for each unique category in a categorical feature. For example, we can one-hot encode the race feature as follows:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\thiag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>income</th>\n","      <th>race_ Amer-Indian-Eskimo</th>\n","      <th>race_ Asian-Pac-Islander</th>\n","      <th>race_ Black</th>\n","      <th>race_ Other</th>\n","      <th>race_ White</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>1</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass  fnlwgt   education  education-num  \\\n","0   39          State-gov   77516   Bachelors             13   \n","1   50   Self-emp-not-inc   83311   Bachelors             13   \n","2   38            Private  215646     HS-grad              9   \n","3   53            Private  234721        11th              7   \n","4   28            Private  338409   Bachelors             13   \n","\n","        marital-status          occupation    relationship  sex  capital-gain  \\\n","0        Never-married        Adm-clerical   Not-in-family    1          2174   \n","1   Married-civ-spouse     Exec-managerial         Husband    1             0   \n","2             Divorced   Handlers-cleaners   Not-in-family    1             0   \n","3   Married-civ-spouse   Handlers-cleaners         Husband    1             0   \n","4   Married-civ-spouse      Prof-specialty            Wife    0             0   \n","\n","   capital-loss  hours-per-week  native-country  income  \\\n","0             0              40   United-States       0   \n","1             0              13   United-States       0   \n","2             0              40   United-States       0   \n","3             0              40   United-States       0   \n","4             0              40            Cuba       0   \n","\n","   race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n","0                       0.0                       0.0          0.0   \n","1                       0.0                       0.0          0.0   \n","2                       0.0                       0.0          0.0   \n","3                       0.0                       0.0          1.0   \n","4                       0.0                       0.0          1.0   \n","\n","   race_ Other  race_ White  \n","0          0.0          1.0  \n","1          0.0          1.0  \n","2          0.0          1.0  \n","3          0.0          0.0  \n","4          0.0          0.0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import OneHotEncoder\n","\n","# Instantiate the OneHotEncoder\n","ohe = OneHotEncoder()\n","\n","# Fit and transform the 'race' feature\n","race_ohe = ohe.fit_transform(df[['race']])\n","\n","# Create a new dataframe with the one-hot encoded 'race' feature\n","race_df = pd.DataFrame(race_ohe.toarray(), columns=ohe.get_feature_names(['race']))\n","\n","# Add the new dataframe to the original dataframe\n","df = pd.concat([df, race_df], axis=1)\n","\n","# Drop the original 'race' feature\n","df.drop('race', axis=1, inplace=True)\n","\n","# Print the first few rows of the dataset\n","df.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Normalization\n","Normalization is the process of scaling numerical features to a common range. This is often necessary for machine learning algorithms that use distance-based measures, such as k-nearest neighbors and support vector machines.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Min-Max Scaling\n","One common method of normalization is min-max scaling. Min-max scaling scales the values of a feature to a range between 0 and 1. For example, we can normalize the age feature as follows:"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Instantiate the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Fit and transform the 'age' feature\n","df['age'] = scaler.fit_transform(df[['age']])\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","Feature selection is the process of selecting a subset of relevant features from our dataset that are most useful for our machine learning model. This can help to reduce overfitting and improve the performance of our model. There are different methods for feature selection, such as filter methods, wrapper methods, and embedded methods.\n","\n","One common filter method for feature selection is correlation analysis, which measures the linear relationship between two variables. We can use the corr() function from pandas to compute the correlation matrix for our dataset:"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>fnlwgt</th>\n","      <th>education-num</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>income</th>\n","      <th>race_ Amer-Indian-Eskimo</th>\n","      <th>race_ Asian-Pac-Islander</th>\n","      <th>race_ Black</th>\n","      <th>race_ Other</th>\n","      <th>race_ White</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>age</th>\n","      <td>1.000000</td>\n","      <td>-0.076646</td>\n","      <td>0.036527</td>\n","      <td>0.088832</td>\n","      <td>0.077674</td>\n","      <td>0.057775</td>\n","      <td>0.068756</td>\n","      <td>0.234037</td>\n","      <td>-0.010137</td>\n","      <td>-0.011111</td>\n","      <td>-0.019434</td>\n","      <td>-0.034415</td>\n","      <td>0.033412</td>\n","    </tr>\n","    <tr>\n","      <th>fnlwgt</th>\n","      <td>-0.076646</td>\n","      <td>1.000000</td>\n","      <td>-0.043195</td>\n","      <td>0.026858</td>\n","      <td>0.000432</td>\n","      <td>-0.010252</td>\n","      <td>-0.018768</td>\n","      <td>-0.009463</td>\n","      <td>-0.064148</td>\n","      <td>-0.051323</td>\n","      <td>0.118009</td>\n","      <td>0.006376</td>\n","      <td>-0.056896</td>\n","    </tr>\n","    <tr>\n","      <th>education-num</th>\n","      <td>0.036527</td>\n","      <td>-0.043195</td>\n","      <td>1.000000</td>\n","      <td>0.012280</td>\n","      <td>0.122630</td>\n","      <td>0.079923</td>\n","      <td>0.148123</td>\n","      <td>0.335154</td>\n","      <td>-0.029345</td>\n","      <td>0.062091</td>\n","      <td>-0.075272</td>\n","      <td>-0.044133</td>\n","      <td>0.051353</td>\n","    </tr>\n","    <tr>\n","      <th>sex</th>\n","      <td>0.088832</td>\n","      <td>0.026858</td>\n","      <td>0.012280</td>\n","      <td>1.000000</td>\n","      <td>0.048480</td>\n","      <td>0.045567</td>\n","      <td>0.229309</td>\n","      <td>0.215980</td>\n","      <td>-0.010820</td>\n","      <td>-0.000856</td>\n","      <td>-0.115604</td>\n","      <td>-0.013906</td>\n","      <td>0.103486</td>\n","    </tr>\n","    <tr>\n","      <th>capital-gain</th>\n","      <td>0.077674</td>\n","      <td>0.000432</td>\n","      <td>0.122630</td>\n","      <td>0.048480</td>\n","      <td>1.000000</td>\n","      <td>-0.031615</td>\n","      <td>0.078409</td>\n","      <td>0.223329</td>\n","      <td>-0.006015</td>\n","      <td>0.009851</td>\n","      <td>-0.020631</td>\n","      <td>-0.001774</td>\n","      <td>0.014429</td>\n","    </tr>\n","    <tr>\n","      <th>capital-loss</th>\n","      <td>0.057775</td>\n","      <td>-0.010252</td>\n","      <td>0.079923</td>\n","      <td>0.045567</td>\n","      <td>-0.031615</td>\n","      <td>1.000000</td>\n","      <td>0.054256</td>\n","      <td>0.150526</td>\n","      <td>-0.012947</td>\n","      <td>0.004469</td>\n","      <td>-0.021762</td>\n","      <td>-0.005964</td>\n","      <td>0.021044</td>\n","    </tr>\n","    <tr>\n","      <th>hours-per-week</th>\n","      <td>0.068756</td>\n","      <td>-0.018768</td>\n","      <td>0.148123</td>\n","      <td>0.229309</td>\n","      <td>0.078409</td>\n","      <td>0.054256</td>\n","      <td>1.000000</td>\n","      <td>0.229689</td>\n","      <td>-0.003096</td>\n","      <td>-0.004564</td>\n","      <td>-0.053153</td>\n","      <td>-0.007188</td>\n","      <td>0.049345</td>\n","    </tr>\n","    <tr>\n","      <th>income</th>\n","      <td>0.234037</td>\n","      <td>-0.009463</td>\n","      <td>0.335154</td>\n","      <td>0.215980</td>\n","      <td>0.223329</td>\n","      <td>0.150526</td>\n","      <td>0.229689</td>\n","      <td>1.000000</td>\n","      <td>-0.028721</td>\n","      <td>0.010543</td>\n","      <td>-0.089089</td>\n","      <td>-0.031830</td>\n","      <td>0.085224</td>\n","    </tr>\n","    <tr>\n","      <th>race_ Amer-Indian-Eskimo</th>\n","      <td>-0.010137</td>\n","      <td>-0.064148</td>\n","      <td>-0.029345</td>\n","      <td>-0.010820</td>\n","      <td>-0.006015</td>\n","      <td>-0.012947</td>\n","      <td>-0.003096</td>\n","      <td>-0.028721</td>\n","      <td>1.000000</td>\n","      <td>-0.017829</td>\n","      <td>-0.031991</td>\n","      <td>-0.008996</td>\n","      <td>-0.237763</td>\n","    </tr>\n","    <tr>\n","      <th>race_ Asian-Pac-Islander</th>\n","      <td>-0.011111</td>\n","      <td>-0.051323</td>\n","      <td>0.062091</td>\n","      <td>-0.000856</td>\n","      <td>0.009851</td>\n","      <td>0.004469</td>\n","      <td>-0.004564</td>\n","      <td>0.010543</td>\n","      <td>-0.017829</td>\n","      <td>1.000000</td>\n","      <td>-0.059144</td>\n","      <td>-0.016632</td>\n","      <td>-0.439572</td>\n","    </tr>\n","    <tr>\n","      <th>race_ Black</th>\n","      <td>-0.019434</td>\n","      <td>0.118009</td>\n","      <td>-0.075272</td>\n","      <td>-0.115604</td>\n","      <td>-0.020631</td>\n","      <td>-0.021762</td>\n","      <td>-0.053153</td>\n","      <td>-0.089089</td>\n","      <td>-0.031991</td>\n","      <td>-0.059144</td>\n","      <td>1.000000</td>\n","      <td>-0.029844</td>\n","      <td>-0.788747</td>\n","    </tr>\n","    <tr>\n","      <th>race_ Other</th>\n","      <td>-0.034415</td>\n","      <td>0.006376</td>\n","      <td>-0.044133</td>\n","      <td>-0.013906</td>\n","      <td>-0.001774</td>\n","      <td>-0.005964</td>\n","      <td>-0.007188</td>\n","      <td>-0.031830</td>\n","      <td>-0.008996</td>\n","      <td>-0.016632</td>\n","      <td>-0.029844</td>\n","      <td>1.000000</td>\n","      <td>-0.221809</td>\n","    </tr>\n","    <tr>\n","      <th>race_ White</th>\n","      <td>0.033412</td>\n","      <td>-0.056896</td>\n","      <td>0.051353</td>\n","      <td>0.103486</td>\n","      <td>0.014429</td>\n","      <td>0.021044</td>\n","      <td>0.049345</td>\n","      <td>0.085224</td>\n","      <td>-0.237763</td>\n","      <td>-0.439572</td>\n","      <td>-0.788747</td>\n","      <td>-0.221809</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               age    fnlwgt  education-num       sex  \\\n","age                       1.000000 -0.076646       0.036527  0.088832   \n","fnlwgt                   -0.076646  1.000000      -0.043195  0.026858   \n","education-num             0.036527 -0.043195       1.000000  0.012280   \n","sex                       0.088832  0.026858       0.012280  1.000000   \n","capital-gain              0.077674  0.000432       0.122630  0.048480   \n","capital-loss              0.057775 -0.010252       0.079923  0.045567   \n","hours-per-week            0.068756 -0.018768       0.148123  0.229309   \n","income                    0.234037 -0.009463       0.335154  0.215980   \n","race_ Amer-Indian-Eskimo -0.010137 -0.064148      -0.029345 -0.010820   \n","race_ Asian-Pac-Islander -0.011111 -0.051323       0.062091 -0.000856   \n","race_ Black              -0.019434  0.118009      -0.075272 -0.115604   \n","race_ Other              -0.034415  0.006376      -0.044133 -0.013906   \n","race_ White               0.033412 -0.056896       0.051353  0.103486   \n","\n","                          capital-gain  capital-loss  hours-per-week  \\\n","age                           0.077674      0.057775        0.068756   \n","fnlwgt                        0.000432     -0.010252       -0.018768   \n","education-num                 0.122630      0.079923        0.148123   \n","sex                           0.048480      0.045567        0.229309   \n","capital-gain                  1.000000     -0.031615        0.078409   \n","capital-loss                 -0.031615      1.000000        0.054256   \n","hours-per-week                0.078409      0.054256        1.000000   \n","income                        0.223329      0.150526        0.229689   \n","race_ Amer-Indian-Eskimo     -0.006015     -0.012947       -0.003096   \n","race_ Asian-Pac-Islander      0.009851      0.004469       -0.004564   \n","race_ Black                  -0.020631     -0.021762       -0.053153   \n","race_ Other                  -0.001774     -0.005964       -0.007188   \n","race_ White                   0.014429      0.021044        0.049345   \n","\n","                            income  race_ Amer-Indian-Eskimo  \\\n","age                       0.234037                 -0.010137   \n","fnlwgt                   -0.009463                 -0.064148   \n","education-num             0.335154                 -0.029345   \n","sex                       0.215980                 -0.010820   \n","capital-gain              0.223329                 -0.006015   \n","capital-loss              0.150526                 -0.012947   \n","hours-per-week            0.229689                 -0.003096   \n","income                    1.000000                 -0.028721   \n","race_ Amer-Indian-Eskimo -0.028721                  1.000000   \n","race_ Asian-Pac-Islander  0.010543                 -0.017829   \n","race_ Black              -0.089089                 -0.031991   \n","race_ Other              -0.031830                 -0.008996   \n","race_ White               0.085224                 -0.237763   \n","\n","                          race_ Asian-Pac-Islander  race_ Black  race_ Other  \\\n","age                                      -0.011111    -0.019434    -0.034415   \n","fnlwgt                                   -0.051323     0.118009     0.006376   \n","education-num                             0.062091    -0.075272    -0.044133   \n","sex                                      -0.000856    -0.115604    -0.013906   \n","capital-gain                              0.009851    -0.020631    -0.001774   \n","capital-loss                              0.004469    -0.021762    -0.005964   \n","hours-per-week                           -0.004564    -0.053153    -0.007188   \n","income                                    0.010543    -0.089089    -0.031830   \n","race_ Amer-Indian-Eskimo                 -0.017829    -0.031991    -0.008996   \n","race_ Asian-Pac-Islander                  1.000000    -0.059144    -0.016632   \n","race_ Black                              -0.059144     1.000000    -0.029844   \n","race_ Other                              -0.016632    -0.029844     1.000000   \n","race_ White                              -0.439572    -0.788747    -0.221809   \n","\n","                          race_ White  \n","age                          0.033412  \n","fnlwgt                      -0.056896  \n","education-num                0.051353  \n","sex                          0.103486  \n","capital-gain                 0.014429  \n","capital-loss                 0.021044  \n","hours-per-week               0.049345  \n","income                       0.085224  \n","race_ Amer-Indian-Eskimo    -0.237763  \n","race_ Asian-Pac-Islander    -0.439572  \n","race_ Black                 -0.788747  \n","race_ Other                 -0.221809  \n","race_ White                  1.000000  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.corr()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>fnlwgt</th>\n","      <th>education</th>\n","      <th>education-num</th>\n","      <th>marital-status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>sex</th>\n","      <th>capital-gain</th>\n","      <th>capital-loss</th>\n","      <th>hours-per-week</th>\n","      <th>native-country</th>\n","      <th>income</th>\n","      <th>race_ Amer-Indian-Eskimo</th>\n","      <th>race_ Asian-Pac-Islander</th>\n","      <th>race_ Black</th>\n","      <th>race_ Other</th>\n","      <th>race_ White</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.301370</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>1</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.452055</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.287671</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.493151</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.150685</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32556</th>\n","      <td>0.136986</td>\n","      <td>Private</td>\n","      <td>257302</td>\n","      <td>Assoc-acdm</td>\n","      <td>12</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Tech-support</td>\n","      <td>Wife</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>32557</th>\n","      <td>0.315068</td>\n","      <td>Private</td>\n","      <td>154374</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Husband</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>32558</th>\n","      <td>0.561644</td>\n","      <td>Private</td>\n","      <td>151910</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Widowed</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>32559</th>\n","      <td>0.068493</td>\n","      <td>Private</td>\n","      <td>201490</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Own-child</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>United-States</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>32560</th>\n","      <td>0.479452</td>\n","      <td>Self-emp-inc</td>\n","      <td>287927</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Wife</td>\n","      <td>0</td>\n","      <td>15024</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32561 rows × 19 columns</p>\n","</div>"],"text/plain":["            age          workclass  fnlwgt    education  education-num  \\\n","0      0.301370          State-gov   77516    Bachelors             13   \n","1      0.452055   Self-emp-not-inc   83311    Bachelors             13   \n","2      0.287671            Private  215646      HS-grad              9   \n","3      0.493151            Private  234721         11th              7   \n","4      0.150685            Private  338409    Bachelors             13   \n","...         ...                ...     ...          ...            ...   \n","32556  0.136986            Private  257302   Assoc-acdm             12   \n","32557  0.315068            Private  154374      HS-grad              9   \n","32558  0.561644            Private  151910      HS-grad              9   \n","32559  0.068493            Private  201490      HS-grad              9   \n","32560  0.479452       Self-emp-inc  287927      HS-grad              9   \n","\n","            marital-status          occupation    relationship  sex  \\\n","0            Never-married        Adm-clerical   Not-in-family    1   \n","1       Married-civ-spouse     Exec-managerial         Husband    1   \n","2                 Divorced   Handlers-cleaners   Not-in-family    1   \n","3       Married-civ-spouse   Handlers-cleaners         Husband    1   \n","4       Married-civ-spouse      Prof-specialty            Wife    0   \n","...                    ...                 ...             ...  ...   \n","32556   Married-civ-spouse        Tech-support            Wife    0   \n","32557   Married-civ-spouse   Machine-op-inspct         Husband    1   \n","32558              Widowed        Adm-clerical       Unmarried    0   \n","32559        Never-married        Adm-clerical       Own-child    1   \n","32560   Married-civ-spouse     Exec-managerial            Wife    0   \n","\n","       capital-gain  capital-loss  hours-per-week  native-country  income  \\\n","0              2174             0              40   United-States       0   \n","1                 0             0              13   United-States       0   \n","2                 0             0              40   United-States       0   \n","3                 0             0              40   United-States       0   \n","4                 0             0              40            Cuba       0   \n","...             ...           ...             ...             ...     ...   \n","32556             0             0              38   United-States       0   \n","32557             0             0              40   United-States       1   \n","32558             0             0              40   United-States       0   \n","32559             0             0              20   United-States       0   \n","32560         15024             0              40   United-States       1   \n","\n","       race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n","0                           0.0                       0.0          0.0   \n","1                           0.0                       0.0          0.0   \n","2                           0.0                       0.0          0.0   \n","3                           0.0                       0.0          1.0   \n","4                           0.0                       0.0          1.0   \n","...                         ...                       ...          ...   \n","32556                       0.0                       0.0          0.0   \n","32557                       0.0                       0.0          0.0   \n","32558                       0.0                       0.0          0.0   \n","32559                       0.0                       0.0          0.0   \n","32560                       0.0                       0.0          0.0   \n","\n","       race_ Other  race_ White  \n","0              0.0          1.0  \n","1              0.0          1.0  \n","2              0.0          1.0  \n","3              0.0          0.0  \n","4              0.0          0.0  \n","...            ...          ...  \n","32556          0.0          1.0  \n","32557          0.0          1.0  \n","32558          0.0          1.0  \n","32559          0.0          1.0  \n","32560          0.0          1.0  \n","\n","[32561 rows x 19 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"could not convert string to float: ' State-gov'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\thiag\\OneDrive\\Desktop\\UERJ - 2023\\uerj-topicos-a\\preprocessing\\preprocessing_pt2.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiag/OneDrive/Desktop/UERJ%20-%202023/uerj-topicos-a/preprocessing/preprocessing_pt2.ipynb#Y136sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Apply SelectKBest and chi2 to select top 10 features\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiag/OneDrive/Desktop/UERJ%20-%202023/uerj-topicos-a/preprocessing/preprocessing_pt2.ipynb#Y136sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m selector \u001b[39m=\u001b[39m SelectKBest(chi2, k\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thiag/OneDrive/Desktop/UERJ%20-%202023/uerj-topicos-a/preprocessing/preprocessing_pt2.ipynb#Y136sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_new \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mfit_transform(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiag/OneDrive/Desktop/UERJ%20-%202023/uerj-topicos-a/preprocessing/preprocessing_pt2.ipynb#Y136sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Get the names of the selected features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiag/OneDrive/Desktop/UERJ%20-%202023/uerj-topicos-a/preprocessing/preprocessing_pt2.ipynb#Y136sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m feature_names \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcolumns[selector\u001b[39m.\u001b[39mget_support(indices\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)]\u001b[39m.\u001b[39mtolist()\n","File \u001b[1;32mc:\\Users\\thiag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n","File \u001b[1;32mc:\\Users\\thiag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:463\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    447\u001b[0m     \u001b[39m\"\"\"Run score function on (X, y) and get the appropriate features.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[0;32m    449\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 463\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    464\u001b[0m         X, y, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    465\u001b[0m     )\n\u001b[0;32m    467\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func):\n\u001b[0;32m    468\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    469\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe score function should be a callable, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) was passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func))\n\u001b[0;32m    471\u001b[0m         )\n","File \u001b[1;32mc:\\Users\\thiag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n","File \u001b[1;32mc:\\Users\\thiag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n","File \u001b[1;32mc:\\Users\\thiag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' State-gov'"]}],"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","X = df.drop('income', axis=1).values\n","y = df['income'].values\n","\n","# Apply SelectKBest and chi2 to select top 10 features\n","selector = SelectKBest(chi2, k=10)\n","X_new = selector.fit_transform(X, y)\n","\n","# Get the names of the selected features\n","feature_names = X.columns[selector.get_support(indices=True)].tolist()\n","\n","print(\"Selected features:\", feature_names)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["categorical_variables = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country']\n","\n","# Instantiate the LabelEncoder\n","for var in categorical_variables:\n","    le = LabelEncoder()\n","    # Fit and transform the 'sex' feature\n","    df[var] = le.fit_transform(df[var])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected features: ['fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']\n"]}],"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","X = df.drop('income', axis=1).values\n","y = df['income'].values\n","\n","X_columns = df.drop('income',axis=1).columns\n","\n","# Apply SelectKBest and chi2 to select top 10 features\n","selector = SelectKBest(chi2, k=10)\n","X_new = selector.fit_transform(X, y)\n","\n","\n","# Get the names of the selected features\n","feature_names = X_columns[selector.get_support(indices=True)].tolist()\n","\n","print(\"Selected features:\", feature_names)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected features: ['age', 'education-num', 'marital-status', 'relationship', 'sex', 'race_ Amer-Indian-Eskimo', 'race_ Asian-Pac-Islander', 'race_ Black', 'race_ Other', 'race_ White']\n"]}],"source":["from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression\n","\n","# Create a logistic regression model\n","model = LinearRegression()\n","\n","# Perform feature selection with RFE\n","rfe = RFE(model, n_features_to_select=10)\n","fit = rfe.fit(X, y)\n","\n","# Get the names of the selected features\n","feature_names = X_columns[fit.support_].tolist()\n","\n","print(\"Selected features:\", feature_names)\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP59uuvpyJRkC9XT9lVxYaV","collapsed_sections":[],"name":"Pre_processamento_1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"d044c6e0ce06759120adefce77398d00e1228e64d92f3f185fbd024a7701b8e0"}}},"nbformat":4,"nbformat_minor":0}
